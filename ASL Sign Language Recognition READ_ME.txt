ğŸ§  ASL Sign Language Recognition
University Deep Learning Project
1- Project Description
This project presents a Deep Learningâ€“based system for recognizing American Sign Language (ASL) letters and words from images and video frame sequences.
The system combines Convolutional Neural Networks (CNNs) for letter recognition with Transformer-based models for word recognition, all integrated into a simple and user-friendly Streamlit graphical interface.
2- Project Objectives
Recognize ASL alphabet letters from single images
Recognize ASL words from sequences of frames
Apply modern Deep Learning techniques (CNNs and Transformers)
Provide an intuitive and easy-to-use graphical user interface
3- System Overview
The system consists of two main recognition pipelines:
ğŸ”¹ Letters Recognition
Model: CNN (ResNet18)
Input: Single image
Output: Predicted ASL letter
ğŸ”¹ Words Recognition
Model: CNN + Transformer Encoder
Input: Sequence of frames
Output: Predicted ASL word
The application is deployed using Streamlit, allowing users to upload images or capture snapshots from a camera and receive predictions visually through the graphical interface.
4- Key Features
ResNet18-based CNN for accurate letter classification
Transformer-based architecture for word-level sequence recognition
Robust preprocessing and data augmentation
Complete training pipeline (Training, Validation, Testing)
Clean and minimal Streamlit GUI
Camera snapshot integration
Automatic class loading using ImageFolder directory structure
5- Project Structure

project/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ letters_model.pth
â”‚   â””â”€â”€ words_model.pth
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ train_letters.py
â”‚   â””â”€â”€ train_words.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â””â”€â”€ model_loader.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
6- Team Members & Responsibilities
Name
Responsibility
Mohamed Emad Elraw
Data preprocessing and augmentation
Zeyad Ahraf
CNN model architecture (Letters)
Sarah Mahrous Mohamed
Model training
Shahd Ahmed Khaled
Validation and testing
Hana Alaa Abderhman
Transformer model (Words recognition)
Youssif Hisham Baiomy
Project documentation
Ahd Said Atia
Camera integration
Omar Abdelhameed
GUI design and model integration
Requirements
Install the required dependencies using: 

Bash
pip install -r requirements.txt
Main Libraries
streamlit
torch
torchvision
numpy
opencv-python
pillow
tqdm
7- How to Run the Project
1ï¸âƒ£ Dataset Preparation
The dataset should follow the ImageFolder format:

dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ class1/
â”‚   â”œâ”€â”€ class2/
â””â”€â”€ test/
    â”œâ”€â”€ class1/
    â”œâ”€â”€ class2/
2ï¸âƒ£ Model Training (Optional)

Bash
python train/train_letters.py
python train/train_words.py
Trained models will be saved in the models/ directory.
3ï¸âƒ£ Run the Application

Bash
streamlit run app.py
8- Training and Evaluation Summary
Letters Model: ResNet18, CrossEntropyLoss, Adam optimizer
Words Model: CNN combined with Transformer Encoder
Evaluation Metrics: Accuracy, Precision, Recall, Confusion Matrix
Overfitting Control: Data augmentation and validation-based checkpointing
9- Future Improvements
Real-time ASL recognition from live video
Sentence-level sign language recognition
Expansion to larger and more diverse datasets
Deployment as a mobile or web-based application
10- Conclusion
This project demonstrates a practical and effective application of Deep Learning, Computer Vision, and Transformer models for American Sign Language recognition, delivering accurate visual predictions through a clean and user-friendly graphical interface.
